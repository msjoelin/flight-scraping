---
title: "Flight Price Web Scraping"
author: "Marcus"
date: "February 14, 2019"
output:
  html_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Flight Web Scraping

### Introduction

I'm a pretty frequent traveller, and this means I have spent some time of searching for flights (actually I dont want to track exactly how much time I have spent on such a crappy task). Price is of course one important factor when deciding exact travel dates, butI guess I'm not the only one noticing the fluctuations in flight prices. Often you find a flight, everything looked good but just had to check a doublecheck the schedule. The next day, all clear, just book the flight - but now the price was waay higher than it was yesterday.  

To take a closer look at this without having to search for flights every day, I wrote an R-script to scrape the web for prices. As some sites are making it hard to scrape the data through an automated script (for example recaptcha), the first step was to identify a site without such issues. After some testing, Expedia turned out to be a good candidate. 

In this text, I will not describe the data collection process. You'll find the scripts for 

### Exploratory Analysis

As always when it comes to analysis, the first step is to load the data and check it out. 

```{r,  message=FALSE, warning=FALSE, echo=FALSE}
library(readr)      # Read data in data 
library(lubridate)  # Date handling
library(stringr)    # Text handling

library(tidyr)      # Data cleaning
library(dplyr)      # Data cleaning

library(ggplot2)    # Visualization

df <- read.csv("flightdata.csv", stringsAsFactors = TRUE)

summary(df)

df <- df %>%
  mutate(DepartureDate=as.Date(as.character(DepartureDate)), 
         ReturnDate=as.Date(as.character(ReturnDate)),
         ScrapeDate=as.Date(as.character(ScrapeDate)))

head(df)

```

* 6 different cities are being evaluated
* Departure, Return and date when the data was scraped is available. This means that we can compare prices of the same TravelDates for different Scraping-dates

Lets check how the data points are distributed between Journey and ScrapeDate. 

```{r,  echo=FALSE}
ggplot(df, aes(x=ScrapeDate, y=Journey, color=Origin))+
  geom_count() + 
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

```

The data for 13th and 14th of January has more datapoints than other dates, but otherwise it looks fine. Some dates are missing as the scraping was not carried out on those dates. Also, there are some gaps in journeys  -the reason is errors during the scraping process. 

For consistency, data before the 15th of January are removed. 

As the prices for `STO-CPH` is by nature much lower than `BER-SIN`, variable with standardized prices `price_std` is created. The standardization is made for each journey / traveldate / scrapingdate, as we want to investigate fluctiations between scrapedates. Standardization means that the variable has mean of 0 and standard deviation of 1, and by doing this, we can compare journeys without using different scales. 


```{r,  message=FALSE, warning=FALSE}
df <- filter(df, ScrapeDate>="2019-01-15") %>%
  group_by(Journey, Origin, TravelDates) %>%
  mutate(price_std = scale(price), # Standardize price per scrapedate
         n=n())  
  
group_by(df, Journey, Origin, TravelDates, n) %>%
  summarize(mean=mean(price_std), 
            stdev = sd(price_std)) %>%
  filter(n>2) %>%
  head(n=10)
```

Lets plot the median value of the standardized prices to identify journeys with high fluctuation in prices. 
A median value above zero indicate that most days, the prices are varying above average. 

```{r,  message=FALSE, warning=FALSE, echo=FALSE}
filter(df, !is.na(price_std)) %>%
ggplot(aes(x=Journey, y=price_std, fill=Origin)) +
  stat_summary(geom="bar", fun.y="median") + 
  geom_hline(yintercept=0) + 
  coord_flip()
```

STO-CPH is having the highest variations, whereas CPH-SIN tends to be very low. 
Notable is also that all flights with origin SIN and BKK are having higher variations, for BER it is the other way round. 

Lets dig a little deeper by checking only flights with origin STO and by plotting the values by days before departure.  


```{r,  message=FALSE, warning=FALSE, echo=FALSE}
filter(df, DaysBeforeDeparture >= 7 & DaysBeforeDeparture <=13 & Origin %in% c("STO")) %>%
ggplot(aes(x=as.factor(DaysBeforeDeparture), y=price_std, fill=Origin)) + 
  geom_boxplot() + 
  facet_grid(Journey~.) + 
  theme(axis.text.x = element_text(size=6),
        axis.text.y = element_text(size=6),
        axis.title.x = element_text("DaysBeforeDeparture"),
        legend.position = "none") + 
  geom_hline(yintercept=0) + 
  coord_flip()
  
```

* `STO-CPH` : The deviations are not varying that much depending on days before departure, but in general the median is well above zero. 
The boxplot is pretty wide, indicationg high variation. 
* `STO-BER` : Prices tends to go up as days before departure goes down. If you see a good price 10 days before departure, be sure to book! 

In general, prices tends to go up the closer departure you get. To what extent, really depends on the journey. 

Lets check out Berlin (as this is my homebase). 


```{r,  message=FALSE, warning=FALSE, echo=FALSE}
filter(df, DaysBeforeDeparture >= 7 & DaysBeforeDeparture <=13 & Origin %in% c("BER")) %>%
ggplot(aes(x=as.factor(DaysBeforeDeparture), y=price_std, fill=Origin)) + 
  geom_boxplot() + 
  facet_grid(Journey~.) + 
  theme(axis.text.x = element_text(size=6),
        axis.text.y = element_text(size=6),
        axis.title.x = element_text("DaysBeforeDeparture"),
        legend.position = "none") + 
  geom_hline(yintercept=0) + 
  coord_flip()
  
```

As for STO-BER, the prices of the reverted journey BER-STO are also considerably pricier closer to departure. The same trend is obvious for BER-CPH. 

Finally, lets break down `BER-STO` and `BER-SIN` on TravelDates and plot the different prices depending on days before departure. 
The tendency that prices are increasing closer to departure more clearly for `BER-STO` is obvious - red points are much higher than for `BER-SIN`. 

```{r,  message=FALSE, warning=FALSE, echo=FALSE}
filter(df, DaysBeforeDeparture >= 7 & DaysBeforeDeparture <=13 & Journey=="BER-STO" & n>6) %>%
ggplot(aes(x=TravelDates, y=price, color=as.factor(DaysBeforeDeparture))) + 
  geom_jitter(size=3, height=0.5, width=0) +
  coord_flip() +
  facet_grid(~Journey) + 
  scale_color_brewer(palette = "RdYlGn") + 
  guides(color=guide_legend(title="DaysBeforeDeparture")) 

filter(df, DaysBeforeDeparture >= 7 & DaysBeforeDeparture <=13 & Journey=="BER-SIN" & n>6) %>%
ggplot(aes(x=TravelDates, y=price, color=as.factor(DaysBeforeDeparture))) + 
  geom_jitter(size=3, height=0.5, width=0) +
  coord_flip() +
  facet_grid(~Journey) + 
  scale_color_brewer(palette = "RdYlGn") + 
  guides(color=guide_legend(title="DaysBeforeDeparture")) 

  
```

To wrap it up, the analysis is summarized in the heatmap below. Red values indicate higher prices.  

```{r,  message=FALSE, warning=FALSE, echo=FALSE}
filter(df, DaysBeforeDeparture >= 7 & DaysBeforeDeparture <=13 & n>=4) %>%
  group_by(Journey, DaysBeforeDeparture) %>%
  summarize(price_deviation = median(price_std, na.rm=TRUE)) %>%
  ggplot(aes(x=as.factor(DaysBeforeDeparture), y=Journey, z=price_deviation, label=round(price_deviation,1))) + 
  geom_tile(aes(fill=price_deviation)) + 
  geom_text(size=3) +  
  xlab("Days Before Departure") + ylab("Journey") + 
  scale_fill_gradient2(low="blue", high="red")
  
```


The prices for Berlin journeys are really skyrocketing. So next time I'm finding a good Berlin price 10 days ahead of departure, I will book it instantly.
