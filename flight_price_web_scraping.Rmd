---
title: "Flight Price Web Scraping"
author: "Marcus"
date: "February 14, 2019"
output:
  html_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Flight Web Scraping

### Introduction

I'm a pretty frequent traveller, and this means I have spent some time of searching for flights (actually I dont want to track exactly how much time I have spent on such a crappy task). Price is of course one important factor when deciding exact travel dates, butI guess I'm not the only one noticing the fluctuations in flight prices. Often you find a flight, everything looked good but just had to check a doublecheck the schedule. The next day, all clear, just book the flight - but now the price was waay higher than it was yesterday.  

To take a closer look at this without having to search for flights every day, I wrote an R-script to scrape the web for prices. As some sites are making it hard to scrape the data through an automated script (for example recaptcha), the first step was to identify a site without such issues. After some testing, Expedia turned out to be a good candidate. 

In this text, I will not describe the data collection but only analyzing. 

### Exploratory Analysis

As always when it comes to analysis, the first step is to load the data and check it out. 

```{r,  message=FALSE, warning=FALSE, echo=FALSE}
library(readr)      # Read data in data 
library(lubridate)  # Date handling
library(stringr)    # Text handling

library(tidyr)      # Data cleaning
library(dplyr)      # Data cleaning

library(ggplot2)    # Visualization

df <- read.csv("flightdata.csv", stringsAsFactors = TRUE)

summary(df)

df <- df %>%
  mutate(DepartureDate=as.Date(as.character(DepartureDate)), 
         ReturnDate=as.Date(as.character(ReturnDate)),
         ScrapeDate=as.Date(as.character(ScrapeDate)))

head(df)

```

* 6 different cities are being evaluated
* Departure, Return and date when the data was scraped is available. This means that we can compare prices of the same TravelDates for different Scraping-dates

Lets check how the data points are distributed between Journey and ScrapeDate. 

```{r,  echo=FALSE}
ggplot(df, aes(x=ScrapeDate, y=Journey, color=Origin))+
  geom_count() + 
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

```

The data for 13th and 14th of January has more datapoints than other dates, but otherwise it looks fine. There are some gaps, which has to do with errors when the scraping was performed. I'll remove the data before the 15th of Januray for consistency along all Journeys. 
In order to compare prices for a given journey and date along the scraping date, a standardized variable `price_std` is created. Standardization means that the variable has mean of 0 and standard deviation of 1. 


```{r,  message=FALSE, warning=FALSE}

df <- 
  filter(df, 
             ScrapeDate>="2019-01-15") %>%
  group_by(Journey, Origin, TravelDates) %>%
  mutate(price_std = scale(price)) # Standardize price per scrapedate

group_by(df, Journey, Origin, TravelDates) %>%
  summarize(n=n(),
            mean=mean(price_std), 
            stdev = sd(price_std)) %>%
  filter(n>1) %>%
  head(n=10)
```

Lets plot the median value of the standardized prices to identify journeys with high fluctuation in prices. 
A median value above zero indicate that most days, the prices are varying above average. 

```{r,  message=FALSE, warning=FALSE, echo=FALSE}
filter(df, !is.na(price_std)) %>%
ggplot(aes(x=Journey, y=price_std, fill=Origin)) +
  stat_summary(geom="bar", fun.y="median") + 
  geom_hline(yintercept=0) + 
  coord_flip()
```

STO-CPH is having the highest variations, whereas CPH-SIN tends to be very low. 
Notable is also that all flights with origin SIN and BKK are having higher variations, for BER it is the other way round. 

Lets dig a little deeper by checking only flights with origin STO and by plotting the values by days before departure.  


```{r,  message=FALSE, warning=FALSE, echo=FALSE}
filter(df, DaysBeforeDeparture >= 7 & DaysBeforeDeparture <=13 & Origin %in% c("STO")) %>%
ggplot(aes(x=as.factor(DaysBeforeDeparture), y=price_std, fill=Origin)) + 
  geom_boxplot() + 
  facet_grid(Journey~.) + 
  theme(axis.text.x = element_text(size=6),
        axis.text.y = element_text(size=6),
        axis.title.x = element_text("DaysBeforeDeparture"),
        legend.position = "none") + 
  geom_hline(yintercept=0) + 
  coord_flip()
  
```

* `STO-CPH` : The deviations are not varying that much depending on days before departure, but in general the median is well above zero. 
The boxplot is pretty wide, indicationg high variation. 
* `STO-BER` : Prices tends to go up as days before departure goes down. If you see a good price 10 days before departure, be sure to book! 

In general, prices tends to go up the closer departure you get. To what extent, really depends on the journey. 

Lets check out Berlin (as this is my homebase). 


```{r,  message=FALSE, warning=FALSE, echo=FALSE}
filter(df, DaysBeforeDeparture >= 7 & DaysBeforeDeparture <=13 & Origin %in% c("BER")) %>%
ggplot(aes(x=as.factor(DaysBeforeDeparture), y=price_std, fill=Origin)) + 
  geom_boxplot() + 
  facet_grid(Journey~.) + 
  theme(axis.text.x = element_text(size=6),
        axis.text.y = element_text(size=6),
        axis.title.x = element_text("DaysBeforeDeparture"),
        legend.position = "none") + 
  geom_hline(yintercept=0) + 
  coord_flip()
  
```


